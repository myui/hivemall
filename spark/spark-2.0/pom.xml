<!--
  Hivemall: Hive scalable Machine Learning Library

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

          http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<parent>
		<groupId>io.github.myui</groupId>
		<artifactId>hivemall</artifactId>
		<version>0.4.2-rc.2</version>
		<relativePath>../../pom.xml</relativePath>
	</parent>

	<artifactId>hivemall-spark</artifactId>
	<name>Hivemall on Spark 2.0</name>
	<packaging>jar</packaging>

	<properties>
		<PermGen>64m</PermGen>
		<MaxPermGen>1024m</MaxPermGen>
		<CodeCacheSize>512m</CodeCacheSize>
	</properties>

	<dependencies>
		<!-- hivemall dependencies -->
		<dependency>
			<groupId>io.github.myui</groupId>
			<artifactId>hivemall-core</artifactId>
			<version>${project.version}</version>
			<scope>compile</scope>
		</dependency>
		<dependency>
			<groupId>io.github.myui</groupId>
			<artifactId>hivemall-xgboost</artifactId>
			<version>${project.version}</version>
			<scope>compile</scope>
		</dependency>
		<dependency>
			<groupId>io.github.myui</groupId>
			<artifactId>hivemall-spark-common</artifactId>
			<version>${project.version}</version>
			<scope>compile</scope>
		</dependency>

		<!-- third-party dependencies -->
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
			<scope>compile</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.commons</groupId>
			<artifactId>commons-compress</artifactId>
			<version>1.8</version>
			<scope>compile</scope>
		</dependency>

		<!-- other provided dependencies -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>

		<!-- test dependencies -->
		<dependency>
			<groupId>io.github.myui</groupId>
			<artifactId>hivemall-mixserv</artifactId>
			<version>${project.version}</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.xerial</groupId>
			<artifactId>xerial-core</artifactId>
			<version>3.2.3</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.scalatest</groupId>
			<artifactId>scalatest_${scala.binary.version}</artifactId>
			<version>2.2.4</version>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<build>
		<directory>target</directory>
		<outputDirectory>target/classes</outputDirectory>
		<finalName>${project.artifactId}-${spark.binary.version}_${scala.binary.version}-${project.version}</finalName>
		<testOutputDirectory>target/test-classes</testOutputDirectory>
		<plugins>
			<!-- For incremental compilation -->
			<plugin>
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<version>3.2.2</version>
				<executions>
					<execution>
						<id>scala-compile-first</id>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
					<execution>
						<id>scala-test-compile-first</id>
						<phase>process-test-resources</phase>
						<goals>
							<goal>testCompile</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<scalaVersion>${scala.version}</scalaVersion>
					<recompileMode>incremental</recompileMode>
					<useZincServer>true</useZincServer>
					<args>
						<arg>-unchecked</arg>
						<arg>-deprecation</arg>
						<!-- TODO: To enable this option, we need to fix many wornings -->
						<!-- <arg>-feature</arg> -->
					</args>
					<jvmArgs>
						<jvmArg>-Xms1024m</jvmArg>
						<jvmArg>-Xmx1024m</jvmArg>
						<jvmArg>-XX:PermSize=${PermGen}</jvmArg>
						<jvmArg>-XX:MaxPermSize=${MaxPermGen}</jvmArg>
						<jvmArg>-XX:ReservedCodeCacheSize=${CodeCacheSize}</jvmArg>
					</jvmArgs>
				</configuration>
			</plugin>
			<!-- hivemall-spark_xx-xx.jar -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-jar-plugin</artifactId>
				<version>2.5</version>
				<configuration>
					<finalName>${project.artifactId}-${spark.binary.version}_${scala.binary.version}-${project.version}</finalName>
					<outputDirectory>${project.parent.build.directory}</outputDirectory>
				</configuration>
			</plugin>
			<!-- hivemall-spark_xx-xx-with-dependencies.jar including minimum dependencies -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<version>2.3</version>
				<executions>
					<execution>
						<id>jar-with-dependencies</id>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
						<configuration>
							<finalName>${project.artifactId}-${spark.binary.version}_${scala.binary.version}-${project.version}-with-dependencies</finalName>
							<outputDirectory>${project.parent.build.directory}</outputDirectory>
							<minimizeJar>false</minimizeJar>
							<createDependencyReducedPom>false</createDependencyReducedPom>
							<artifactSet>
								<includes>
									<include>io.github.myui:hivemall-core</include>
									<include>io.github.myui:hivemall-xgboost</include>
									<include>io.github.myui:hivemall-spark-common</include>
									<include>com.github.haifengl:smile-core</include>
									<include>com.github.haifengl:smile-math</include>
									<include>com.github.haifengl:smile-data</include>
									<include>ml.dmlc:xgboost4j</include>
									<include>com.esotericsoftware.kryo:kryo</include>
								</includes>
							</artifactSet>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<!-- disable surefire because there is no java test -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<version>2.7</version>
				<configuration>
					<skipTests>true</skipTests>
				</configuration>
			</plugin>
			<!-- then, enable scalatest -->
			<plugin>
				<groupId>org.scalatest</groupId>
				<artifactId>scalatest-maven-plugin</artifactId>
				<version>1.0</version>
				<configuration>
					<reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
					<junitxml>.</junitxml>
					<filereports>SparkTestSuite.txt</filereports>
					<argLine>-Xmx1024m -XX:MaxPermSize=${MaxPermGen} -XX:ReservedCodeCacheSize=${CodeCacheSize}</argLine>
					<stderr/>
					<environmentVariables>
						<SPARK_PREPEND_CLASSES>1</SPARK_PREPEND_CLASSES>
						<SPARK_SCALA_VERSION>${scala.binary.version}</SPARK_SCALA_VERSION>
						<SPARK_TESTING>1</SPARK_TESTING>
						<JAVA_HOME>${env.JAVA_HOME}</JAVA_HOME>
					</environmentVariables>
					<systemProperties>
						<log4j.configuration>file:src/test/resources/log4j.properties</log4j.configuration>
						<derby.system.durability>test</derby.system.durability>
						<java.awt.headless>true</java.awt.headless>
						<java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>
						<spark.testing>1</spark.testing>
						<spark.ui.enabled>false</spark.ui.enabled>
						<spark.ui.showConsoleProgress>false</spark.ui.showConsoleProgress>
						<spark.unsafe.exceptionOnMemoryLeak>true</spark.unsafe.exceptionOnMemoryLeak>
						<!-- Needed by sql/hive tests. -->
						<test.src.tables>__not_used__</test.src.tables>
					</systemProperties>
					<tagsToExclude>${test.exclude.tags}</tagsToExclude>
				</configuration>
				<executions>
					<execution>
						<id>test</id>
						<goals>
							<goal>test</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>
</project>
